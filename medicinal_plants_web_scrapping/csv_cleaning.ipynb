{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9996e5e-1229-4531-b371-2c37af943490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "âœ… Loaded 310 rows and 15 columns\n",
      "Columns: ['scientific_name', 'common_names', 'family', 'description', 'parts_used', 'therapeutic_category', 'uses_and_properties', 'active_ingredients', 'pharmacological_effects', 'notes', 'warning', 'status', 'alternative_names', 'origin', 'dosage']\n",
      "\n",
      "1. Cleaning column names...\n",
      "âœ… Cleaned columns: ['Scientific Name', 'Common Names', 'Family', 'Description', 'Parts Used', 'Therapeutic Category', 'Uses And Properties', 'Active Ingredients', 'Pharmacological Effects', 'Notes', 'Warning', 'Status', 'Alternative Names', 'Origin', 'Dosage']\n",
      "\n",
      "2. Cleaning text fields...\n",
      "âœ… Text cleaned\n",
      "\n",
      "3. Fixing common names...\n",
      "âœ… Common names separated\n",
      "\n",
      "4. Removing duplicates...\n",
      "âœ… Removed 0 duplicates\n",
      "\n",
      "5. Handling missing values...\n",
      "Missing values per column:\n",
      "  Family: 306 (98.7%)\n",
      "  Parts Used: 3 (1.0%)\n",
      "  Therapeutic Category: 8 (2.6%)\n",
      "  Uses And Properties: 130 (41.9%)\n",
      "  Active Ingredients: 164 (52.9%)\n",
      "  Pharmacological Effects: 137 (44.2%)\n",
      "  Notes: 238 (76.8%)\n",
      "  Warning: 310 (100.0%)\n",
      "  Dosage: 261 (84.2%)\n",
      "\n",
      "6. Adding quality scores...\n",
      "âœ… Quality scores calculated\n",
      "\n",
      "7. Exporting cleaned data...\n",
      "âœ… Saved: medicinal_plants_cleaned.csv\n",
      "âœ… Saved: medicinal_plants_high_quality.csv (145 plants)\n",
      "âœ… Saved: medicinal_plants_very_high_quality.csv (2 plants)\n",
      "\n",
      "======================================================================\n",
      "CLEANING REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Dataset Overview:\n",
      "  Total plants: 310\n",
      "  Unique families: 4\n",
      "  Columns: 20\n",
      "\n",
      "âœ… Data Quality:\n",
      "  Plants with Family: 4 (1.3%)\n",
      "  Plants with Description: 310 (100.0%)\n",
      "  Plants with Uses: 180 (58.1%)\n",
      "  Plants with Active Ingredients: 146 (47.1%)\n",
      "  Average Completeness: 51.6%\n",
      "\n",
      "ðŸ“ˆ Quality Distribution:\n",
      "  >75% complete: 2 plants\n",
      "  >50% complete: 145 plants\n",
      "  <50% complete: 165 plants\n",
      "\n",
      "ðŸ† Top 10 Most Complete Entries:\n",
      "  Aronia melanocarpa             | black chokeberry               | 100%\n",
      "  Astragalus membranaceus        | astragalus membranous milk vetch | 100%\n",
      "  Achillea millefolium           | yarrow milfoil woundwort       | 75%\n",
      "  Actaea racemosa                | black cohosh black snakeroot   | 75%\n",
      "  Adonis vernalis                | yellow pheasantâ€™s eye spring adonis | 75%\n",
      "  Aesculus hippocastanum         | horse chestnut                 | 75%\n",
      "  Allium sativum                 | garlic                         | 75%\n",
      "  Aloe ferox                     | bitter aloe Cape aloe          | 75%\n",
      "  Aloysia citrodora              | lemon verbena vervain          | 75%\n",
      "  Alpinia officinarum            | galangal Siamese ginger lesser galangal | 75%\n",
      "\n",
      "âš ï¸  Bottom 10 Least Complete Entries:\n",
      "  Aconitum napellus              | aconite monkshood wolfsbane    | 25%\n",
      "  Acorus calamus                 | calamus sweet flag flag root   | 25%\n",
      "  Agathosma betulina             | buchu round leaf buchu         | 25%\n",
      "  Agrimonia eupatoria            | common agrimony                | 25%\n",
      "  Alchemilla xanthochlora        | ladyâ€™s mantle                  | 25%\n",
      "  Allium cepa                    | onion                          | 25%\n",
      "  Allium ursinum                 | wild garlic bearâ€™s garlic ramsons | 25%\n",
      "  Aloe vera                      | aloe vera CuraÃ§ao aloe         | 25%\n",
      "  Ananas comosus                 | pineapple                      | 25%\n",
      "  Anethum graveolens             | dill                           | 25%\n",
      "\n",
      "âœ… Summary saved to: cleaning_summary.json\n",
      "\n",
      "======================================================================\n",
      "âœ… CLEANING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ Files created:\n",
      "  1. medicinal_plants_cleaned.csv - Full cleaned dataset\n",
      "  2. medicinal_plants_high_quality.csv - Plants >50% complete\n",
      "  3. medicinal_plants_very_high_quality.csv - Plants >75% complete\n",
      "  4. cleaning_summary.json - Statistics summary\n",
      "\n",
      "ðŸ“‹ Sample of cleaned data:\n",
      "           Scientific Name                         Common Names    Family  \\\n",
      "0               Abies alba       silver fir European silver fir  Pinaceae   \n",
      "1     Achillea millefolium             yarrow milfoil woundwort      None   \n",
      "2        Aconitum napellus          aconite monkshood wolfsbane      None   \n",
      "3           Acorus calamus         calamus sweet flag flag root      None   \n",
      "4          Actaea racemosa         black cohosh black snakeroot      None   \n",
      "5          Adonis vernalis  yellow pheasantâ€™s eye spring adonis      None   \n",
      "6   Aesculus hippocastanum                       horse chestnut      None   \n",
      "7       Agathosma betulina               buchu round leaf buchu      None   \n",
      "8      Agrimonia eupatoria                      common agrimony      None   \n",
      "9  Alchemilla xanthochlora                        ladyâ€™s mantle      None   \n",
      "\n",
      "   Completeness_Score  \n",
      "0                50.0  \n",
      "1                75.0  \n",
      "2                25.0  \n",
      "3                25.0  \n",
      "4                75.0  \n",
      "5                75.0  \n",
      "6                75.0  \n",
      "7                25.0  \n",
      "8                25.0  \n",
      "9                25.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('medicinal_plants.csv', encoding='utf-8')\n",
    "print(f\"âœ… Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "print(f\"Columns: {list(df.columns)}\\n\")\n",
    "\n",
    "# 1. Clean column names\n",
    "print(\"1. Cleaning column names...\")\n",
    "df.columns = df.columns.str.strip().str.replace('_', ' ').str.title()\n",
    "print(f\"âœ… Cleaned columns: {list(df.columns)}\\n\")\n",
    "\n",
    "# 2. Clean text in all columns\n",
    "print(\"2. Cleaning text fields...\")\n",
    "text_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in text_columns:\n",
    "    # Convert to string and strip whitespace\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    # Replace multiple spaces with single space\n",
    "    df[col] = df[col].str.replace(r'\\s+', ' ', regex=True)\n",
    "    # Replace 'nan' with empty string\n",
    "    df[col] = df[col].replace('nan', '')\n",
    "    df[col] = df[col].replace('NaN', '')\n",
    "\n",
    "print(\"âœ… Text cleaned\\n\")\n",
    "\n",
    "# 3. Split common names properly\n",
    "print(\"3. Fixing common names...\")\n",
    "if 'Common Names' in df.columns:\n",
    "    # Split names that are concatenated (separated by 2+ spaces)\n",
    "    df['Common Names'] = df['Common Names'].apply(\n",
    "        lambda x: ', '.join([name.strip() for name in re.split(r'\\s{2,}', str(x)) if name.strip()])\n",
    "    )\n",
    "    print(\"âœ… Common names separated\\n\")\n",
    "\n",
    "# 4. Remove duplicates\n",
    "print(\"4. Removing duplicates...\")\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=['Scientific Name'], keep='first')\n",
    "after = len(df)\n",
    "print(f\"âœ… Removed {before - after} duplicates\\n\")\n",
    "\n",
    "# 5. Replace empty strings with None\n",
    "print(\"5. Handling missing values...\")\n",
    "df = df.replace('', None)\n",
    "df = df.replace('N/A', None)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "for col, count in missing.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# 6. Add data quality flags\n",
    "print(\"6. Adding quality scores...\")\n",
    "df['Has_Description'] = df['Description'].notna() & (df['Description'].str.len() > 50)\n",
    "df['Has_Uses'] = df['Uses And Properties'].notna() & (df['Uses And Properties'].str.len() > 20)\n",
    "df['Has_Active_Ingredients'] = df['Active Ingredients'].notna() & (df['Active Ingredients'].str.len() > 20)\n",
    "df['Has_Family'] = df['Family'].notna() & (df['Family'].str.len() > 0)\n",
    "\n",
    "# Calculate completeness score\n",
    "df['Completeness_Score'] = (\n",
    "    df[['Has_Description', 'Has_Uses', 'Has_Active_Ingredients', 'Has_Family']].sum(axis=1) / 4 * 100\n",
    ").round(0)\n",
    "\n",
    "print(\"âœ… Quality scores calculated\\n\")\n",
    "\n",
    "# 7. Export cleaned data\n",
    "print(\"7. Exporting cleaned data...\")\n",
    "\n",
    "# Full dataset\n",
    "df.to_csv('medicinal_plants_cleaned.csv', index=False, encoding='utf-8')\n",
    "print(\"âœ… Saved: medicinal_plants_cleaned.csv\")\n",
    "\n",
    "# High quality only (>50% complete)\n",
    "high_quality = df[df['Completeness_Score'] > 50]\n",
    "high_quality.to_csv('medicinal_plants_high_quality.csv', index=False, encoding='utf-8')\n",
    "print(f\"âœ… Saved: medicinal_plants_high_quality.csv ({len(high_quality)} plants)\")\n",
    "\n",
    "# Very high quality (>75% complete)\n",
    "very_high_quality = df[df['Completeness_Score'] > 75]\n",
    "very_high_quality.to_csv('medicinal_plants_very_high_quality.csv', index=False, encoding='utf-8')\n",
    "print(f\"âœ… Saved: medicinal_plants_very_high_quality.csv ({len(very_high_quality)} plants)\\n\")\n",
    "\n",
    "# 8. Generate summary report\n",
    "print(\"=\"*70)\n",
    "print(\"CLEANING REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"  Total plants: {len(df)}\")\n",
    "print(f\"  Unique families: {df['Family'].nunique()}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\nâœ… Data Quality:\")\n",
    "print(f\"  Plants with Family: {df['Has_Family'].sum()} ({df['Has_Family'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Plants with Description: {df['Has_Description'].sum()} ({df['Has_Description'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Plants with Uses: {df['Has_Uses'].sum()} ({df['Has_Uses'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Plants with Active Ingredients: {df['Has_Active_Ingredients'].sum()} ({df['Has_Active_Ingredients'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Average Completeness: {df['Completeness_Score'].mean():.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Quality Distribution:\")\n",
    "print(f\"  >75% complete: {len(very_high_quality)} plants\")\n",
    "print(f\"  >50% complete: {len(high_quality)} plants\")\n",
    "print(f\"  <50% complete: {len(df[df['Completeness_Score'] <= 50])} plants\")\n",
    "\n",
    "print(f\"\\nðŸ† Top 10 Most Complete Entries:\")\n",
    "top_10 = df.nlargest(10, 'Completeness_Score')[['Scientific Name', 'Common Names', 'Family', 'Completeness_Score']]\n",
    "for idx, row in top_10.iterrows():\n",
    "    names = row['Common Names'][:50] if row['Common Names'] else 'N/A'\n",
    "    print(f\"  {row['Scientific Name']:30} | {names:30} | {row['Completeness_Score']:.0f}%\")\n",
    "\n",
    "print(f\"\\nâš ï¸  Bottom 10 Least Complete Entries:\")\n",
    "bottom_10 = df.nsmallest(10, 'Completeness_Score')[['Scientific Name', 'Common Names', 'Completeness_Score']]\n",
    "for idx, row in bottom_10.iterrows():\n",
    "    names = row['Common Names'][:50] if row['Common Names'] else 'N/A'\n",
    "    print(f\"  {row['Scientific Name']:30} | {names:30} | {row['Completeness_Score']:.0f}%\")\n",
    "\n",
    "# Save summary to JSON\n",
    "summary = {\n",
    "    'total_plants': len(df),\n",
    "    'plants_with_family': int(df['Has_Family'].sum()),\n",
    "    'plants_with_description': int(df['Has_Description'].sum()),\n",
    "    'plants_with_uses': int(df['Has_Uses'].sum()),\n",
    "    'plants_with_active_ingredients': int(df['Has_Active_Ingredients'].sum()),\n",
    "    'average_completeness': float(df['Completeness_Score'].mean()),\n",
    "    'high_quality_plants': len(high_quality),\n",
    "    'very_high_quality_plants': len(very_high_quality)\n",
    "}\n",
    "\n",
    "with open('cleaning_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Summary saved to: cleaning_summary.json\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… CLEANING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ’¡ Files created:\")\n",
    "print(\"  1. medicinal_plants_cleaned.csv - Full cleaned dataset\")\n",
    "print(\"  2. medicinal_plants_high_quality.csv - Plants >50% complete\")\n",
    "print(\"  3. medicinal_plants_very_high_quality.csv - Plants >75% complete\")\n",
    "print(\"  4. cleaning_summary.json - Statistics summary\")\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\nðŸ“‹ Sample of cleaned data:\")\n",
    "print(df[['Scientific Name', 'Common Names', 'Family', 'Completeness_Score']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c30a86-74c2-4f5a-ac22-821315ad4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading medicinal plants dataset...\n",
      "Successfully loaded dataset with 310 rows and 20 columns\n",
      "\n",
      "Original columns:\n",
      "  - Scientific Name\n",
      "  - Common Names\n",
      "  - Family\n",
      "  - Description\n",
      "  - Parts Used\n",
      "  - Therapeutic Category\n",
      "  - Uses And Properties\n",
      "  - Active Ingredients\n",
      "  - Pharmacological Effects\n",
      "  - Notes\n",
      "  - Warning\n",
      "  - Status\n",
      "  - Alternative Names\n",
      "  - Origin\n",
      "  - Dosage\n",
      "  - Has_Description\n",
      "  - Has_Uses\n",
      "  - Has_Active_Ingredients\n",
      "  - Has_Family\n",
      "  - Completeness_Score\n",
      "Starting data cleaning process...\n",
      "Cleaning complete. Processed 310 plants.\n",
      "\n",
      "==================================================\n",
      "CLEANING RESULTS ANALYSIS\n",
      "==================================================\n",
      "Original dataset shape: (310, 20)\n",
      "Cleaned dataset shape: (310, 22)\n",
      "Description: 310/310 (100.0%) non-empty\n",
      "Active_Ingredients: 274/310 (88.4%) non-empty\n",
      "Pharmacological_Effects: 74/310 (23.9%) non-empty\n",
      "Traditional_Uses: 170/310 (54.8%) non-empty\n",
      "\n",
      "SAMPLE OF CLEANED DATA (first 3 plants):\n",
      "==================================================\n",
      "\n",
      "1. Abies alba\n",
      "   Family: Pinaceae\n",
      "   Active Ingredients: Fir needle oil contains vola- Cones are typically erect and disintegrates at maturity. tile terpenoi...\n",
      "   Uses: The oil is added to baths 60 m in height). The narrowly linear leaves are glossy or used as inhalant...\n",
      "\n",
      "2. Achillea millefolium\n",
      "   Family: \n",
      "   Active Ingredients: Pyrrolidine alkaloids indications. (betonicine and stachydrine), flavonoids and volatiles\n",
      "   Uses: The herb is traditionally and are mainly ascribed to the sesquiterpene lactones used to treat arthri...\n",
      "\n",
      "3. Aconitum napellus\n",
      "   Family: \n",
      "   Active Ingredients: Aconitum contains numerous of western and central Europe. Several species are diterpenoid alkaloids ...\n",
      "   Uses: \n",
      "\n",
      "Cleaning report saved to 'cleaning_report.txt'\n",
      "Cleaned dataset saved to 'medicinal_plants_cleaned_final.xlsx'\n",
      "\n",
      "Cleaning process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_medicinal_plants_dataset(df):\n",
    "    \"\"\"\n",
    "    Main function to clean and reorganize the medicinal plants dataset\n",
    "    \"\"\"\n",
    "    print(\"Starting data cleaning process...\")\n",
    "    \n",
    "    # Create a new cleaned dataframe\n",
    "    cleaned_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['Scientific Name']) or row['Scientific Name'] == '':\n",
    "            continue\n",
    "            \n",
    "        plant_data = {\n",
    "            'Scientific_Name': clean_text(row['Scientific Name']),\n",
    "            'Common_Names': clean_text(row['Common Names']),\n",
    "            'Family': clean_text(row['Family']),\n",
    "            'Description': extract_description(row),\n",
    "            'Parts_Used': extract_parts_used(row),\n",
    "            'Therapeutic_Category': extract_therapeutic_category(row),\n",
    "            'Traditional_Uses': extract_traditional_uses(row),\n",
    "            'Active_Ingredients': extract_active_ingredients(row),\n",
    "            'Pharmacological_Effects': extract_pharmacological_effects(row),\n",
    "            'Dosage_Instructions': extract_dosage_instructions(row),\n",
    "            'Warnings': extract_warnings(row),\n",
    "            'Origin_Distribution': extract_origin_distribution(row),\n",
    "            'Cultivation_Status': extract_cultivation_status(row),\n",
    "            'Preparation_Methods': extract_preparation_methods(row),\n",
    "            'Clinical_Status': extract_clinical_status(row),\n",
    "            'Alternative_Names': clean_text(row['Alternative Names']),\n",
    "            'Additional_Notes': extract_additional_notes(row),\n",
    "            'Has_Description': row.get('Has_Description', ''),\n",
    "            'Has_Uses': row.get('Has_Uses', ''),\n",
    "            'Has_Active_Ingredients': row.get('Has_Active_Ingredients', ''),\n",
    "            'Has_Family': row.get('Has_Family', ''),\n",
    "            'Completeness_Score': row.get('Completeness_Score', '')\n",
    "        }\n",
    "        cleaned_data.append(plant_data)\n",
    "    \n",
    "    cleaned_df = pd.DataFrame(cleaned_data)\n",
    "    print(f\"Cleaning complete. Processed {len(cleaned_df)} plants.\")\n",
    "    return cleaned_df\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and standardize text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def extract_description(row):\n",
    "    \"\"\"Extract plant description\"\"\"\n",
    "    desc = clean_text(row.get('Description', ''))\n",
    "    if not desc or desc in ['', 'nan']:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove content that belongs to other sections\n",
    "    stop_patterns = [\n",
    "        r'active ingredients.*',\n",
    "        r'pharmacological effects.*',\n",
    "        r'origin.*',\n",
    "        r'parts used.*',\n",
    "        r'therapeutic category.*',\n",
    "        r'uses and properties.*'\n",
    "    ]\n",
    "    \n",
    "    for pattern in stop_patterns:\n",
    "        desc = re.split(pattern, desc, flags=re.IGNORECASE)[0]\n",
    "    \n",
    "    return desc.strip()\n",
    "\n",
    "def extract_parts_used(row):\n",
    "    \"\"\"Extract parts used information\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Parts Used', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Uses And Properties', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        if 'parts used' in source.lower() or 'parts useD' in source.lower():\n",
    "            content = extract_after_keyword(source, 'parts used')\n",
    "            if content:\n",
    "                return content\n",
    "    \n",
    "    # Fallback to Parts Used column\n",
    "    parts_used = clean_text(row.get('Parts Used', ''))\n",
    "    if parts_used and parts_used not in ['', 'nan']:\n",
    "        return parts_used\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_therapeutic_category(row):\n",
    "    \"\"\"Extract therapeutic category\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Therapeutic Category', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Uses And Properties', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        if 'therapeutic category' in source.lower():\n",
    "            content = extract_after_keyword(source, 'therapeutic category')\n",
    "            if content:\n",
    "                return content\n",
    "    \n",
    "    # Fallback to Therapeutic Category column\n",
    "    category = clean_text(row.get('Therapeutic Category', ''))\n",
    "    if category and category not in ['', 'nan']:\n",
    "        return category\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_traditional_uses(row):\n",
    "    \"\"\"Extract traditional uses and properties\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Uses And Properties', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Pharmacological Effects', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if any(keyword in lower_source for keyword in ['uses and properties', 'uses anD properties', 'traditional use', 'used to treat']):\n",
    "            if 'uses and properties' in lower_source:\n",
    "                content = extract_after_keyword(source, 'uses and properties')\n",
    "            elif 'uses anD properties' in lower_source:\n",
    "                content = extract_after_keyword(source, 'uses anD properties')\n",
    "            else:\n",
    "                content = source\n",
    "            \n",
    "            if content:\n",
    "                # Clean the content\n",
    "                content = remove_section(content, 'pharmacological effects')\n",
    "                content = remove_section(content, 'active ingredients')\n",
    "                content = remove_section(content, 'warning')\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_active_ingredients(row):\n",
    "    \"\"\"Extract active ingredients information\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Active Ingredients', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Origin', '')),\n",
    "        clean_text(row.get('Pharmacological Effects', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if any(keyword in lower_source for keyword in ['active ingredients', 'active ingreDients', 'main compound', 'contains']):\n",
    "            if 'active ingredients' in lower_source:\n",
    "                content = extract_after_keyword(source, 'active ingredients')\n",
    "            elif 'active ingreDients' in lower_source:\n",
    "                content = extract_after_keyword(source, 'active ingreDients')\n",
    "            else:\n",
    "                # Try to extract relevant portion\n",
    "                content = extract_ingredients_content(source)\n",
    "            \n",
    "            if content and len(content) > 10:  # Meaningful content\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_pharmacological_effects(row):\n",
    "    \"\"\"Extract pharmacological effects\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Pharmacological Effects', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Uses And Properties', '')),\n",
    "        clean_text(row.get('Notes', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if 'pharmacological effects' in lower_source:\n",
    "            content = extract_after_keyword(source, 'pharmacological effects')\n",
    "            if content:\n",
    "                content = remove_section(content, 'uses and properties')\n",
    "                content = remove_section(content, 'warning')\n",
    "                content = remove_section(content, 'notes')\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_dosage_instructions(row):\n",
    "    \"\"\"Extract dosage instructions\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Dosage', '')),\n",
    "        clean_text(row.get('Uses And Properties', '')),\n",
    "        clean_text(row.get('Notes', '')),\n",
    "        clean_text(row.get('Description', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if any(keyword in lower_source for keyword in ['dosage', 'preparation and dosage', 'dose']):\n",
    "            if 'preparation and dosage' in lower_source:\n",
    "                content = extract_after_keyword(source, 'preparation and dosage')\n",
    "            elif 'dosage' in lower_source:\n",
    "                content = extract_after_keyword(source, 'dosage')\n",
    "            else:\n",
    "                content = extract_dosage_content(source)\n",
    "            \n",
    "            if content:\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_warnings(row):\n",
    "    \"\"\"Extract warnings and precautions\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Warning', '')),\n",
    "        clean_text(row.get('Notes', '')),\n",
    "        clean_text(row.get('Uses And Properties', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Pharmacological Effects', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if 'warning' in lower_source:\n",
    "            content = extract_after_keyword(source, 'warning')\n",
    "            if content:\n",
    "                content = remove_section(content, 'notes')\n",
    "                content = remove_section(content, 'status')\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_origin_distribution(row):\n",
    "    \"\"\"Extract origin and distribution information\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Origin', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Notes', ''))\n",
    "    ]\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if 'origin' in lower_source:\n",
    "            content = extract_after_keyword(source, 'origin')\n",
    "            if content:\n",
    "                content = remove_section(content, 'active ingredients')\n",
    "                content = remove_section(content, 'pharmacological effects')\n",
    "                content = remove_section(content, 'parts used')\n",
    "                return content.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_cultivation_status(row):\n",
    "    \"\"\"Extract cultivation status\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Origin', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Notes', ''))\n",
    "    ]\n",
    "    \n",
    "    cultivation_keywords = ['cultivated', 'wild', 'harvested', 'cultivation', 'grown', 'plantation']\n",
    "    \n",
    "    for source in sources:\n",
    "        for keyword in cultivation_keywords:\n",
    "            if keyword in source.lower():\n",
    "                # Extract sentence or context around the keyword\n",
    "                sentences = re.split(r'[.!?]', source)\n",
    "                for sentence in sentences:\n",
    "                    if keyword in sentence.lower():\n",
    "                        return sentence.strip()\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_preparation_methods(row):\n",
    "    \"\"\"Extract preparation methods\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Dosage', '')),\n",
    "        clean_text(row.get('Uses And Properties', '')),\n",
    "        clean_text(row.get('Notes', ''))\n",
    "    ]\n",
    "    \n",
    "    preparation_keywords = ['infusion', 'tincture', 'decoction', 'extract', 'tea', 'ointment', 'powder']\n",
    "    \n",
    "    methods = []\n",
    "    for source in sources:\n",
    "        for keyword in preparation_keywords:\n",
    "            if keyword in source.lower():\n",
    "                # Extract relevant sentences\n",
    "                sentences = re.split(r'[.!?]', source)\n",
    "                for sentence in sentences:\n",
    "                    if keyword in sentence.lower():\n",
    "                        methods.append(sentence.strip())\n",
    "    \n",
    "    return ' '.join(methods) if methods else \"\"\n",
    "\n",
    "def extract_clinical_status(row):\n",
    "    \"\"\"Extract clinical and regulatory status\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Status', '')),\n",
    "        clean_text(row.get('Notes', ''))\n",
    "    ]\n",
    "    \n",
    "    status_keywords = ['clinical', 'pharm', 'traditional', 'who', 'commission', 'escop', 'hmpc']\n",
    "    \n",
    "    status_info = []\n",
    "    for source in sources:\n",
    "        for keyword in status_keywords:\n",
    "            if keyword in source.lower():\n",
    "                # Extract the relevant line or section\n",
    "                lines = source.split('\\n')\n",
    "                for line in lines:\n",
    "                    if keyword in line.lower():\n",
    "                        status_info.append(line.strip())\n",
    "    \n",
    "    return ' | '.join(status_info) if status_info else \"\"\n",
    "\n",
    "def extract_additional_notes(row):\n",
    "    \"\"\"Extract additional notes\"\"\"\n",
    "    sources = [\n",
    "        clean_text(row.get('Notes', '')),\n",
    "        clean_text(row.get('Description', '')),\n",
    "        clean_text(row.get('Uses And Properties', ''))\n",
    "    ]\n",
    "    \n",
    "    notes_keywords = ['notes', 'note:', 'additional', 'also known', 'related species']\n",
    "    \n",
    "    for source in sources:\n",
    "        lower_source = source.lower()\n",
    "        if 'notes' in lower_source:\n",
    "            content = extract_after_keyword(source, 'notes')\n",
    "            if content:\n",
    "                return content.strip()\n",
    "    \n",
    "    # If no specific notes section, use the Notes column\n",
    "    notes = clean_text(row.get('Notes', ''))\n",
    "    if notes and notes not in ['', 'nan']:\n",
    "        return notes\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "# Helper functions\n",
    "def extract_after_keyword(text, keyword):\n",
    "    \"\"\"Extract content after a specific keyword\"\"\"\n",
    "    pattern = r'{}(.*)'.format(re.escape(keyword))\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def remove_section(text, section_name):\n",
    "    \"\"\"Remove a specific section from text\"\"\"\n",
    "    pattern = r'{}(.*)'.format(re.escape(section_name))\n",
    "    return re.split(pattern, text, flags=re.IGNORECASE)[0].strip()\n",
    "\n",
    "def extract_ingredients_content(text):\n",
    "    \"\"\"Extract ingredients-related content\"\"\"\n",
    "    # Look for patterns that indicate ingredient information\n",
    "    ingredient_indicators = [\n",
    "        r'contains.*?[.!?]',\n",
    "        r'main compounds?.*?[.!?]',\n",
    "        r'active compounds?.*?[.!?]',\n",
    "        r'ingredients?.*?[.!?]'\n",
    "    ]\n",
    "    \n",
    "    for pattern in ingredient_indicators:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            return ' '.join(matches)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_dosage_content(text):\n",
    "    \"\"\"Extract dosage-related content\"\"\"\n",
    "    dosage_indicators = [\n",
    "        r'dose.*?[.!?]',\n",
    "        r'dosage.*?[.!?]',\n",
    "        r'take.*?[0-9].*?[.!?]',\n",
    "        r'[0-9].*?g.*?[.!?]',\n",
    "        r'[0-9].*?mg.*?[.!?]',\n",
    "        r'[0-9].*?ml.*?[.!?]'\n",
    "    ]\n",
    "    \n",
    "    dosage_info = []\n",
    "    for pattern in dosage_indicators:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        dosage_info.extend(matches)\n",
    "    \n",
    "    return ' '.join(dosage_info) if dosage_info else \"\"\n",
    "\n",
    "def analyze_cleaning_results(cleaned_df, original_df):\n",
    "    \"\"\"Analyze the results of the cleaning process\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANING RESULTS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"Original dataset shape: {original_df.shape}\")\n",
    "    print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "    \n",
    "    # Check completeness of key columns\n",
    "    key_columns = ['Description', 'Active_Ingredients', 'Pharmacological_Effects', 'Traditional_Uses']\n",
    "    for col in key_columns:\n",
    "        non_empty = cleaned_df[col].apply(lambda x: len(str(x)) > 10).sum()\n",
    "        percentage = (non_empty / len(cleaned_df)) * 100\n",
    "        print(f\"{col}: {non_empty}/{len(cleaned_df)} ({percentage:.1f}%) non-empty\")\n",
    "    \n",
    "    # Show sample of cleaned data\n",
    "    print(\"\\nSAMPLE OF CLEANED DATA (first 3 plants):\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(min(3, len(cleaned_df))):\n",
    "        plant = cleaned_df.iloc[i]\n",
    "        print(f\"\\n{i+1}. {plant['Scientific_Name']}\")\n",
    "        print(f\"   Family: {plant['Family']}\")\n",
    "        print(f\"   Active Ingredients: {plant['Active_Ingredients'][:100]}{'...' if len(str(plant['Active_Ingredients'])) > 100 else ''}\")\n",
    "        print(f\"   Uses: {plant['Traditional_Uses'][:100]}{'...' if len(str(plant['Traditional_Uses'])) > 100 else ''}\")\n",
    "\n",
    "def export_cleaning_report(cleaned_df, output_file='cleaning_report.txt'):\n",
    "    \"\"\"Generate a detailed cleaning report\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"MEDICINAL PLANTS DATA CLEANING REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total plants processed: {len(cleaned_df)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"COLUMN COMPLETENESS:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for col in cleaned_df.columns:\n",
    "            non_empty = cleaned_df[col].apply(lambda x: len(str(x)) > 10).sum()\n",
    "            percentage = (non_empty / len(cleaned_df)) * 100\n",
    "            f.write(f\"{col:25} : {non_empty:3d}/{len(cleaned_df):3d} ({percentage:5.1f}%)\\n\")\n",
    "\n",
    "# MAIN EXECUTION - This is what you run\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete cleaning process\"\"\"\n",
    "    \n",
    "    # Load your Excel file\n",
    "    try:\n",
    "        print(\"Loading medicinal plants dataset...\")\n",
    "        df = pd.read_csv('medicinal_plants_cleaned.csv')\n",
    "        print(f\"Successfully loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        \n",
    "        # Display original column names for verification\n",
    "        print(\"\\nOriginal columns:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"  - {col}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File 'medicinal_plants_cleaned.xlsx' not found.\")\n",
    "        print(\"Please make sure the file is in the same directory as this script.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Clean the dataset\n",
    "    cleaned_df = clean_medicinal_plants_dataset(df)\n",
    "    \n",
    "    # Analyze results\n",
    "    analyze_cleaning_results(cleaned_df, df)\n",
    "    \n",
    "    # Generate report\n",
    "    export_cleaning_report(cleaned_df)\n",
    "    print(f\"\\nCleaning report saved to 'cleaning_report.txt'\")\n",
    "    \n",
    "    # Save cleaned data\n",
    "    output_filename = 'medicinal_plants_cleaned_final.xlsx'\n",
    "    cleaned_df.to_excel(output_filename, index=False)\n",
    "    print(f\"Cleaned dataset saved to '{output_filename}'\")\n",
    "    \n",
    "    print(\"\\nCleaning process completed successfully!\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af797ab-a319-439b-b892-d1c6cde24b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
