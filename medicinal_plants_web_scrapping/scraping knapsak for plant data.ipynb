{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7cf456-97dd-46e1-bfdf-9ff1adf25f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SIMPLE WEBMD MEDICINAL PLANT SCRAPER\n",
      "======================================================================\n",
      "\n",
      "This script will:\n",
      "1. Visit WebMD's herb list (letter A)\n",
      "2. Get the first 5 herbs\n",
      "3. Extract detailed information for each herb\n",
      "4. Save everything to a CSV file\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Getting list of herbs from WebMD...\n",
      "âœ— Problem: Got status code 404\n",
      "\n",
      "âœ— No herbs were scraped. There may be a problem with the website.\n",
      "Try visiting the URL manually to check if it's accessible.\n"
     ]
    }
   ],
   "source": [
    "# Simple WebMD Medicinal Plant Scraper\n",
    "# This script discovers medicinal plants from WebMD and extracts their information\n",
    "\n",
    "# Step 1: Import the tools we need\n",
    "import requests  # This helps us visit websites (like opening a browser)\n",
    "from bs4 import BeautifulSoup  # This helps us read and understand HTML\n",
    "import pandas as pd  # This helps us organize data in tables (like Excel)\n",
    "import time  # This helps us add delays between requests\n",
    "\n",
    "# Step 2: Set up our \"browser\"\n",
    "# Websites need to know what's visiting them, so we pretend to be a regular browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "}\n",
    "\n",
    "# Step 3: Define the main function that gets a list of herbs\n",
    "def get_herb_list():\n",
    "    \"\"\"\n",
    "    This function gets a list of all herbs from WebMD's alphabetical listing.\n",
    "    We'll start with just letter 'A' to keep it simple.\n",
    "    \"\"\"\n",
    "    print(\"Getting list of herbs from WebMD...\")\n",
    "    \n",
    "    # The URL where WebMD lists herbs starting with 'A'\n",
    "    url = \"https://www.webmd.com/vitamins-and-supplements/vitamins-supplements-a-z-list/a\"\n",
    "    \n",
    "    # Step 3.1: Visit the webpage\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        # Check if the page loaded successfully (status code 200 means success)\n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ“ Successfully connected to WebMD\")\n",
    "        else:\n",
    "            print(f\"âœ— Problem: Got status code {response.status_code}\")\n",
    "            return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error connecting to website: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Step 3.2: Parse (read and understand) the HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Step 3.3: Find all the herb links\n",
    "    # On WebMD, herb links look like: /vitamins/ai/ingredientmono-XXX/name\n",
    "    herb_links = soup.find_all('a', href=lambda href: href and '/vitamins/ai/ingredientmono-' in href)\n",
    "    \n",
    "    print(f\"âœ“ Found {len(herb_links)} herbs starting with 'A'\")\n",
    "    \n",
    "    # Step 3.4: Create a list to store herb information\n",
    "    herb_list = []\n",
    "    \n",
    "    # Step 3.5: Go through each herb link (but limit to 5 for now to test)\n",
    "    for i, link in enumerate(herb_links[:5], 1):\n",
    "        # Get the herb name from the link text\n",
    "        herb_name = link.get_text(strip=True)\n",
    "        \n",
    "        # Get the full URL to the herb's page\n",
    "        herb_url = \"https://www.webmd.com\" + link['href']\n",
    "        \n",
    "        print(f\"\\n[{i}/5] Processing: {herb_name}\")\n",
    "        print(f\"    URL: {herb_url}\")\n",
    "        \n",
    "        # Get detailed information about this herb\n",
    "        herb_info = get_herb_details(herb_url, herb_name)\n",
    "        \n",
    "        if herb_info:\n",
    "            herb_list.append(herb_info)\n",
    "            print(f\"    âœ“ Successfully extracted information\")\n",
    "        else:\n",
    "            print(f\"    âœ— Could not extract information\")\n",
    "        \n",
    "        # Wait 2 seconds before visiting the next page (being polite to the server)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return herb_list\n",
    "\n",
    "\n",
    "# Step 4: Define function to get details from each herb's page\n",
    "def get_herb_details(url, herb_name):\n",
    "    \"\"\"\n",
    "    This function visits an individual herb's page and extracts all the details.\n",
    "    \n",
    "    Args:\n",
    "        url: The web address of the herb's page\n",
    "        herb_name: The name of the herb\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary (like a mini-database) with all the herb information\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Visit the herb's page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Create a dictionary to store all information\n",
    "        herb_data = {\n",
    "            'Plant_Name': herb_name,\n",
    "            'Source': 'WebMD',\n",
    "            'URL': url,\n",
    "            'Scientific_Name': '',\n",
    "            'Other_Names': '',\n",
    "            'Target_Function': '',\n",
    "            'Activity_Level': '',\n",
    "            'Part_Used': '',\n",
    "            'Key_Phytochemicals': '',\n",
    "            'Extraction_Method': '',\n",
    "            'Dosage_Range': '',\n",
    "            'Contraindications': ''\n",
    "        }\n",
    "        \n",
    "        # Step 4.1: Look for \"Also Known As\" section (contains other names)\n",
    "        # We search for text that contains \"Also Known As\"\n",
    "        aka_heading = soup.find(text=lambda t: t and 'Also Known As' in t)\n",
    "        if aka_heading:\n",
    "            # Get the parent element (the container holding this text)\n",
    "            aka_section = aka_heading.find_parent()\n",
    "            if aka_section:\n",
    "                # Get all the text and clean it up\n",
    "                aka_text = aka_section.get_text(strip=True)\n",
    "                # Remove the \"Also Known As:\" part\n",
    "                aka_text = aka_text.replace('Also Known As:', '').strip()\n",
    "                herb_data['Other_Names'] = aka_text[:500]  # Limit to 500 characters\n",
    "        \n",
    "        # Step 4.2: Look for scientific name\n",
    "        # Often in italics or in the \"Also Known As\" section\n",
    "        scientific_names = soup.find_all('i')  # Italic text often contains scientific names\n",
    "        for name in scientific_names:\n",
    "            name_text = name.get_text(strip=True)\n",
    "            # Scientific names have format: Genus species\n",
    "            if len(name_text.split()) == 2 and name_text[0].isupper():\n",
    "                herb_data['Scientific_Name'] = name_text\n",
    "                break\n",
    "        \n",
    "        # Step 4.3: Look for \"Uses\" section\n",
    "        uses_heading = soup.find(['h2', 'h3'], text=lambda t: t and 'Uses' in t)\n",
    "        if uses_heading:\n",
    "            # Get the content after this heading\n",
    "            uses_content = uses_heading.find_next(['p', 'div', 'ul'])\n",
    "            if uses_content:\n",
    "                uses_text = uses_content.get_text(strip=True)\n",
    "                herb_data['Target_Function'] = uses_text[:1000]  # Limit to 1000 characters\n",
    "        \n",
    "        # Step 4.4: Look for \"How does it work?\" section (contains phytochemicals/mechanism)\n",
    "        how_heading = soup.find(['h2', 'h3'], text=lambda t: t and 'How does it work' in t)\n",
    "        if how_heading:\n",
    "            how_content = how_heading.find_next(['p', 'div'])\n",
    "            if how_content:\n",
    "                how_text = how_content.get_text(strip=True)\n",
    "                herb_data['Key_Phytochemicals'] = how_text[:1000]\n",
    "        \n",
    "        # Step 4.5: Look for dosing information\n",
    "        dosing_heading = soup.find(['h2', 'h3'], text=lambda t: t and 'Dosing' in t)\n",
    "        if dosing_heading:\n",
    "            dosing_content = dosing_heading.find_next(['p', 'div', 'ul'])\n",
    "            if dosing_content:\n",
    "                dosing_text = dosing_content.get_text(strip=True)\n",
    "                herb_data['Dosage_Range'] = dosing_text[:1000]\n",
    "        \n",
    "        # Step 4.6: Look for safety/interactions/side effects\n",
    "        # Check multiple possible headings\n",
    "        safety_keywords = ['Side Effects', 'Safety', 'Interactions', 'Precautions', 'Warnings']\n",
    "        for keyword in safety_keywords:\n",
    "            safety_heading = soup.find(['h2', 'h3'], text=lambda t: t and keyword in t)\n",
    "            if safety_heading:\n",
    "                safety_content = safety_heading.find_next(['p', 'div', 'ul'])\n",
    "                if safety_content:\n",
    "                    safety_text = safety_content.get_text(strip=True)\n",
    "                    # Append to contraindications (may find multiple sections)\n",
    "                    if herb_data['Contraindications']:\n",
    "                        herb_data['Contraindications'] += ' | ' + safety_text[:500]\n",
    "                    else:\n",
    "                        herb_data['Contraindications'] = safety_text[:500]\n",
    "        \n",
    "        return herb_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Step 5: Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"SIMPLE WEBMD MEDICINAL PLANT SCRAPER\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nThis script will:\")\n",
    "    print(\"1. Visit WebMD's herb list (letter A)\")\n",
    "    print(\"2. Get the first 5 herbs\")\n",
    "    print(\"3. Extract detailed information for each herb\")\n",
    "    print(\"4. Save everything to a CSV file\")\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Get the list of herbs with their details\n",
    "    herbs = get_herb_list()\n",
    "    \n",
    "    # Step 6: Save to CSV (like Excel)\n",
    "    if herbs:\n",
    "        # Convert list of dictionaries to a DataFrame (table)\n",
    "        df = pd.DataFrame(herbs)\n",
    "        \n",
    "        # Save to CSV file\n",
    "        filename = 'webmd_herbs_simple.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"SUCCESS! Found {len(herbs)} herbs\")\n",
    "        print(f\"Data saved to: {filename}\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        \n",
    "        # Show a preview of what we got\n",
    "        print(\"\\nPREVIEW OF DATA:\")\n",
    "        print(\"-\"*70)\n",
    "        for herb in herbs:\n",
    "            print(f\"\\nðŸŒ¿ {herb['Plant_Name']}\")\n",
    "            if herb['Scientific_Name']:\n",
    "                print(f\"   Scientific: {herb['Scientific_Name']}\")\n",
    "            if herb['Target_Function']:\n",
    "                uses = herb['Target_Function'][:100] + \"...\" if len(herb['Target_Function']) > 100 else herb['Target_Function']\n",
    "                print(f\"   Uses: {uses}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"\\nYou can now open 'webmd_herbs_simple.csv' in Excel!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nâœ— No herbs were scraped. There may be a problem with the website.\")\n",
    "        print(\"Try visiting the URL manually to check if it's accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac61cc-888f-44b4-8143-64507bfaf0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
